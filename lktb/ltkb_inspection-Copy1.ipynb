{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit.Chem.PandasTools as pt\n",
    "from matplotlib.pyplot import plot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from usrcat.toolkits.rd import generate_moments\n",
    "from usrcat.sim import *\n",
    "from rdkit.Chem import PandasTools as pt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltkb = pd.read_csv(\"../lktb_inchis.csv\")\n",
    "print(ltkb.shape)\n",
    "ltkb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map severity classes to strings\n",
    "\n",
    "ltkb[\"SEVERITY_CLASS\"] = ltkb[\"SEVERITY_CLASS\"].map( {0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5: '5', 6 :'6', 7:'7', 8:'8'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ATCs to subcodes\n",
    "\n",
    "ltkb[\"ATC_CODE\"] = ltkb[\"ATC_CODE\"].fillna(\"-\")\n",
    "ATCs = ltkb[\"ATC_CODE\"]\n",
    "\n",
    "atc_1 = []\n",
    "atc_2 = []\n",
    "atc_3 = []\n",
    "atc_4 = []\n",
    "atc_5 = []\n",
    "\n",
    "\n",
    "for el in ATCs.tolist():\n",
    "    try:\n",
    "        el = el.split(\" \")[0]\n",
    "        if len(el) == 7:\n",
    "            atc_1.append(el[0])\n",
    "            atc_2.append(el[0:3])\n",
    "            atc_3.append(el[0:4])\n",
    "            atc_4.append(el[0:5])\n",
    "            atc_5.append(el[0:7])\n",
    "        else:\n",
    "            atc_1.append(\"-\")\n",
    "            atc_2.append(\"-\")\n",
    "            atc_3.append(\"-\")\n",
    "            atc_4.append(\"-\")\n",
    "            atc_5.append(\"-\")            \n",
    "\n",
    "    except:\n",
    "        print (el)\n",
    "        atc_1.append(\"-\")\n",
    "        atc_2.append(\"-\")\n",
    "        atc_3.append(\"-\")\n",
    "        atc_4.append(\"-\")\n",
    "        atc_5.append(\"-\")\n",
    "\n",
    "ltkb[\"ATC_1\"] = atc_1\n",
    "ltkb[\"ATC_2\"] = atc_2\n",
    "ltkb[\"ATC_3\"] = atc_3\n",
    "ltkb[\"ATC_4\"] = atc_4\n",
    "ltkb[\"ATC_5\"] = atc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltkb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=ltkb[\"ATC_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the tag availability for the database\n",
    "\n",
    "n_entries = []\n",
    "for col in ltkb.columns:\n",
    "    n_entries.append(ltkb[col].describe()[\"count\"])\n",
    "    \n",
    "n_entries = np.asarray(n_entries).reshape(1, -1)\n",
    "n_entries = pd.DataFrame(n_entries, columns=ltkb.columns.tolist())\n",
    "n_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove compounds with no InChI\n",
    "\n",
    "ltkb = ltkb.fillna(\"-\")\n",
    "ltkb = ltkb[ltkb[\"InChI\"] !=\"-\"]\n",
    "ltkb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of different severity_class tag\n",
    "\n",
    "sns.countplot(ltkb[\"SEVERITY_CLASS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute USR-CAT moments\n",
    "\n",
    "def get_moments(mols):\n",
    "    matrix = np.zeros((len(mols), 600))\n",
    "    for index, mol in enumerate(mols):\n",
    "        try:\n",
    "            vector = np.ravel(generate_moments(mol))\n",
    "            matrix[index, :] = vector\n",
    "        except:\n",
    "            sys.exit(-1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mols from InChIs\n",
    "\n",
    "ltkb[\"ROMol\"] = [AllChem.MolFromInchi(i) for i in ltkb[\"InChI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get conformations for compounds\n",
    "errors = []\n",
    "for index, row in ltkb.iterrows():\n",
    "    try:\n",
    "        AllChem.EmbedMultipleConfs(row[\"ROMol\"], numConfs=10)\n",
    "    except:\n",
    "        print (\"error at index \", index)\n",
    "        errors.append(index)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subframe with no erroneus compounds at computing conformers \n",
    "\n",
    "ltkb_1 = ltkb[~ltkb.index.isin(errors)].reset_index(drop=True)\n",
    "erroneus = []\n",
    "for index, row in ltkb_1.iterrows():\n",
    "    if len(row[\"ROMol\"].GetConformers()) != 10:\n",
    "        erroneus.append(index)\n",
    "ltkb_1 = ltkb_1[~ltkb_1.index.isin(erroneus)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get USR-CAT moments\n",
    "\n",
    "matrix = get_moments(ltkb_1[\"ROMol\"].tolist())\n",
    "dili = pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's cluster ltkb compounds by their 3D-shape/pharmacophoric properties\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=30, random_state=46)\n",
    "km.fit(matrix)\n",
    "ltkb_1[\"cluster\"] = km.labels_\n",
    "mols = ltkb_1[\"ROMol\"].tolist()\n",
    "\n",
    "# Save the file to open it again with PandasTool (to see molecule depiction)\n",
    "pt.WriteSDF(ltkb_1, \"dili_cluster3d.sdf\", properties=ltkb_1.columns)\n",
    "ltkb_1 = pt.LoadSDF(\"dili_cluster3d.sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the cluster column to integer\n",
    "\n",
    "ltkb_1[\"cluster\"] = ltkb_1[\"cluster\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltkb_bk = ltkb_1.copy()\n",
    "new = ltkb_bk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[\"cluster2\"] = \"\"\n",
    "for cluster in np.unique(new[\"cluster\"]):\n",
    "    subset = new[new[\"cluster\"] == cluster]\n",
    "    morgans = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, useFeatures=False) for mol in subset[\"ROMol\"]]\n",
    "    if len(morgans) > 10:\n",
    "        #n_clu = int(len(morgans) * 0.2)\n",
    "        n_clu = 5\n",
    "        km = KMeans(n_clusters=n_clu, random_state=46)\n",
    "        km.fit(morgans)\n",
    "        subset[\"cluster2\"] = km.labels_\n",
    "        for index, row in subset.iterrows():\n",
    "            new.at[index, \"cluster2\"] = row[\"cluster2\"]\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(new[\"ATC_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new.sort_values(by=[\"cluster\", \"cluster2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # [\"SEVERITY_CLASS\", \"ATC_CODE\"]\n",
    "    \n",
    "    \n",
    "most = new[new[\"VERIFIED_DILI_CONCERN\"] == \"vMost-DILI-Concern\"]\n",
    "no = new[new[\"VERIFIED_DILI_CONCERN\"] == \"vNo-DILI-Concern\"]\n",
    "\n",
    "grid = sns.FacetGrid(new[[\"cluster\", \"cluster2\",\"VERIFIED_DILI_CONCERN\", \"ATC_1\"]], \n",
    "                     col=\"cluster2\", row=\"cluster\",\n",
    "                     size=3, aspect=1, legend_out=False, sharex=False)\n",
    "\n",
    "\n",
    "# Draw a horizontal line to show the starting point\n",
    "\n",
    "# Draw a line plot to show the trajectory of each random walk\n",
    "fig = grid.map(sns.countplot, \"ATC_1\", palette=\"Blues\",\n",
    "               order=np.unique(new[\"ATC_1\"]))\n",
    "\n",
    "fig.set_xticklabels(rotation=90)\n",
    "# Adjust the tick positions and labels\n",
    "# fig.set(xticks=np.arange(9))\n",
    "#          #xlim=(-0.5, 9.5) )\n",
    "\n",
    "fig.add_legend()\n",
    "# Adjust the arrangement of the plots\n",
    "fig.savefig(\"test.png\",dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new.sort_values(by=[\"cluster\", \"cluster2\"])[[\"ROMol\", \"cluster\", \"cluster2\",\"ATC_CODE\", \"SEVERITY_CLASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = new.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2[\"SEVERITY_CLASS\"] = new2[\"SEVERITY_CLASS\"].replace(\"-\", 0).astype(int)\n",
    "new2[\"SEVERITY_CLASS\"] = new2[\"SEVERITY_CLASS\"].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = new2.groupby(by=[\"cluster\",\"cluster2\", \"ATC_1\"])[\"SEVERITY_CLASS\"].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
